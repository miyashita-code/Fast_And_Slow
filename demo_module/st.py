from typing import Callable, List, NamedTuple
import asyncio
from pydantic import BaseModel
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_fireworks import ChatFireworks
from langchain_core.runnables import RunnableSequence
from dotenv import load_dotenv
import threading

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# LLMã®å‡ºåŠ›ãƒ¢ãƒ‡ãƒ«
class CheckIsExplainedOutput(BaseModel):
    thought: str
    is_explained: bool

class CheckIsFinishedOutput(BaseModel):
    thought: str
    is_finished: bool

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
check_is_explained_prompt = """
Your Task:
You need to check whether the user's responses sufficiently explain the given detail within the context of the conversation flow. If the responses explain the detail clearly, respond with 'True'. Otherwise, respond with 'False'. Additionally, include a thought process explaining why you reached that conclusion.

Here is the overall conversation flow (for context):
{global_responses}

Here are the user's specific responses to be checked:
{responses}

Here is the specific detail that needs to be explained:
{detail}

Follow these output format instructions (100%, only json output):
{format_instructions}

caution:
even if there are no user responses to check, jsonä»¥å¤–ã§ç­”ãˆã‚‹ãªï¼ä¸€æ–‡å­—ã‚‚è¿½åŠ ã™ã‚‹ãªï¼
"""

check_is_finished_prompt = """
Your Task:
You need to check whether the user's responses sufficiently indicate that the current topic is finished and ready to move to the next topic. If the user's responses sufficiently address the topic, respond with 'True'. Otherwise, respond with 'False'. Additionally, include a thought process explaining why you reached that conclusion.

Here is the overall conversation flow (for context):
{global_responses}

Here are the user's specific responses to be checked:
{responses}

Here is the current topic (detail) that needs to be addressed:
{detail}

Here is the name of the next state or topic we plan to transition to:
{next_state_name}

Follow these output format instructions (100%, only json output):
{format_instructions}

caution:
even if there are no user responses to check, jsonä»¥å¤–ã§ç­”ãˆã‚‹ãªï¼ä¸€æ–‡å­—ã‚‚è¿½åŠ ã™ã‚‹ãªï¼, ã€Œæ¬¡ã¯ï¼Ÿã€ã¨ã‹è¨€ã‚ã‚ŒãŸã‚‰ã™ãã«æ¬¡ã«è¡Œã‘ï¼æ¬¡ã®å†…å®¹ã®è©±ã‚’å§‹ã‚ã¦ã‚‚ã™ãã«æ¬¡ã«è¡Œã‘ï¼
"""

# å‡ºåŠ›ãƒ‘ãƒ¼ã‚µãƒ¼
output_parser_check_is_explained = JsonOutputParser(pydantic_object=CheckIsExplainedOutput)
output_parser_check_is_finished = JsonOutputParser(pydantic_object=CheckIsFinishedOutput)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
prompt_template_check_is_explained = PromptTemplate.from_template(
    check_is_explained_prompt,
    partial_variables={
        "format_instructions": output_parser_check_is_explained.get_format_instructions()
    }
)

prompt_template_check_is_finished = PromptTemplate.from_template(
    check_is_finished_prompt,
    partial_variables={
        "format_instructions": output_parser_check_is_finished.get_format_instructions()
    }
)

# LLMãƒ¢ãƒ‡ãƒ«
fast_model = ChatFireworks(model="accounts/fireworks/models/llama-v3-70b-instruct", max_tokens=4096)

# å®Ÿè¡Œã‚·ãƒ¼ã‚±ãƒ³ã‚¹
check_is_explained_chain = prompt_template_check_is_explained | fast_model | output_parser_check_is_explained
check_is_finished_chain = prompt_template_check_is_finished | fast_model | output_parser_check_is_finished

# ãƒ¡ã‚¤ãƒ³ã®ä¼šè©±ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
class State(NamedTuple):
    detail: str
    name: str
    time: int
    next_state: str = ""
    title: str = ""

class LinearConversationController:
    def __init__(self, llm_client, threshold: float = 0.7):
        self.states = self.get_init_state()
        self.current_state_index = 0
        self.llm_client = llm_client
        self.threshold = threshold
        self.is_on = False
        self.is_explained = False
        self.responses_buffer = []
        self.global_responses_buffer = []
        self.callback = None
        self.direct_prompting_func = None
        self.timer = None
        self.timeout_count = 0
        self.thread = None
        self.state_changed = False  # çŠ¶æ…‹å¤‰åŒ–ã‚’è¿½è·¡ã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
        self.loop = None  # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’åˆæœŸåŒ–

    def set_callbacks(self, callback: Callable, direct_prompting_func: Callable):
        self.callback = callback
        self.direct_prompting_func = direct_prompting_func

    """
    def get_init_state(self) -> List[State]:
        return [
            State(detail="iphoneã®mapã®ä½¿ã„æ–¹ã‚’èª¬æ˜ã—ã¾ã™ã€‚", name="iphoneã®mapã®ä½¿ã„æ–¹èª¬æ˜", time=0, next_state="iphoneã®ãƒ›ãƒ¼ãƒ ç”»é¢ã‚’é–‹ã", title="iphoneã®mapã®ä½¿ã„æ–¹èª¬æ˜"),
            State(detail="ã¾ãšã¯iphoneã‚’æ‰‹ã«å–ã‚Š, é›»æºã‚’å…¥ã‚Œã¦ãƒ›ãƒ¼ãƒ ç”»é¢ã‚’é–‹ã„ã¦ãã ã•ã„ã€‚", name="iphoneã®ãƒ›ãƒ¼ãƒ ç”»é¢ã‚’é–‹ã", time=0, next_state="ãƒãƒƒãƒ— ã‚¢ãƒ—ãƒªã‚’é–‹ã", title="iphoneã®ãƒ›ãƒ¼ãƒ ç”»é¢ã‚’é–‹ã"),
            State(detail="ã¾ãšã¯ã€mapã®ã‚¢ãƒ—ãƒªã®ä¸­ã«å…¥ã‚ŠãŸã„ã®ã§ã€ç”»é¢ã®å³ä¸‹ã®æ–¹ã«ã‚ã‚‹ã€Œãƒãƒƒãƒ— ã‚¢ãƒ—ãƒªã‚’é–‹ã„ã¦ãã ã•ã„ã€", name="ãƒãƒƒãƒ— ã‚¢ãƒ—ãƒªã‚’é–‹ã", time=1, next_state="ãƒãƒƒãƒ—ã§æ¤œç´¢ã‚’ã‚¿ãƒƒãƒ—", title="ç”»é¢å³ä¸‹ã®ãƒãƒƒãƒ— ã‚¢ãƒ—ãƒªã‚’é–‹ã"),
            State(detail="ãƒãƒƒãƒ—ã‚’é–‹ã„ãŸã‚‰ã€ç›®çš„åœ°ã‚’æ¤œç´¢ã—ã¾ã™ã€‚ç”»é¢ã®ä¸‹ã®æ–¹ã®è™«çœ¼é¡ã®ã‚¢ã‚¤ã‚³ãƒ³ã®æ¨ªã«ã€Œãƒãƒƒãƒ—ã§æ¤œç´¢ã€ã¨æ›¸ã„ã¦ã‚ã‚‹ã¨ã“ã‚ã‚’ã‚¿ãƒƒãƒ—ã‹é•·æŠ¼ã—ã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãŒå‡ºã¦ãã¾ã™ã€‚", name="ãƒãƒƒãƒ—ã§æ¤œç´¢ã‚’ã‚¿ãƒƒãƒ—", time=0, next_state="ç›®çš„åœ°ã‚’å…¥åŠ›", title="ã€ŒğŸ”ãƒãƒƒãƒ—ã§æ¤œç´¢ã€ã‚’ã‚¿ãƒƒãƒ—"),
            State(detail="ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ãŒå‡ºã¦ããŸã‚‰ã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã§ç›®çš„åœ°ã®ä½æ‰€ã‹åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚å…¥åŠ›å¾Œã€å…¥åŠ›æ¬„ã®ä¸‹ã«è¡¨ç¤ºã•ã‚ŒãŸå€™è£œã®ä¸­ã‹ã‚‰ç›®çš„ã®ã‚‚ã®ã‚’è¦‹ã¤ã‘ã¦ã‚¿ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚", name="ç›®çš„åœ°ã‚’å…¥åŠ›", time=1, next_state="çµŒè·¯ãƒœã‚¿ãƒ³ã‚’ã‚¿ãƒƒãƒ—", title="ç›®çš„åœ°ã‚’ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã§å…¥åŠ›"),
            State(detail="ç”»é¢ä¸‹éƒ¨ã«é’è‰²ã®ãƒœã‚¿ãƒ³ã§ã€ŒçµŒè·¯ã€ã¨æ›¸ã„ã¦ã‚ã‚‹ãƒœã‚¿ãƒ³ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ãƒœã‚¿ãƒ³ã‚’ã‚¿ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚ãã†ã™ã‚Œã°å‡ºç™ºåœ°ã‚’é¸æŠã®ç”»é¢ãŒå‡ºã¦ãã¾ã™ã€‚ã‚‚ã—ãªã„å ´åˆã¯ä¸‹ã«éš ã‚Œã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã§ã™ã€‚", name="çµŒè·¯ãƒœã‚¿ãƒ³ã‚’ã‚¿ãƒƒãƒ—", time=0, next_state="ç¾åœ¨åœ°ã‚’é¸æŠ", title="ç”»é¢ä¸‹éƒ¨ã®é’è‰²ã®çµŒè·¯ãƒœã‚¿ãƒ³ã‚’ã‚¿ãƒƒãƒ—"),
            State(detail="å‡ºç™ºåœ°ç‚¹ã®å…¥åŠ›ã‚’æ±‚ã‚ã‚‰ã‚ŒãŸã‚‰ã€ç¾åœ¨åœ°ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚ãã®ã‚ã¨ã€å³ä¸Šã®é’è‰²ã®çµŒè·¯ã‚’é¸æŠã—ã¾ã™ã€‚", name="ç¾åœ¨åœ°ã‚’é¸æŠ", time=0, next_state="å‡ºç™º", title="å‡ºç™ºåœ°ã«ç¾åœ¨åœ°ã‚’é¸æŠ"),
            State(detail="ã‚ã¨ã¯ç”»é¢ä¸‹éƒ¨å³ä¸‹ã®å‡ºç™ºã‚’ã‚¿ãƒƒãƒ—ã—ã¦ã€å‡ºç™ºã§ã™ï¼ãŠæ°—ã‚’ã¤ã‘ã¦ï¼", name="å‡ºç™º", time=0, next_state="çµ‚äº†", title="å‡ºç™ºã‚’ã‚¿ãƒƒãƒ—ã—ã¦ãŠæ°—ã‚’ã¤ã‘ã¦ï¼"),
        ]
    """

    def get_init_state(self) -> List[State]:

        return [
            State(
                detail="æ•£æ­©ã«è¡Œãã¾ã›ã‚“ã‹ï¼Ÿ",
                name="ç€æ›¿ãˆã‚’ã™ã‚‹",
                time=0,
                next_state="ä¸Šç€ã‚’ç€ã‚‹",
                title="æ•£æ­©ã«è¡Œãã¾ã›ã‚“ã‹ï¼Ÿ ç€æ›¿ãˆã‚’ã™ã‚‹"
            ),
            State(
                detail="å¤–ã«è¡Œãå‰ã«æœè£…ã ã‘æ•´ãˆãŸã„ã§ã™ã­ã€‚ä»Šæ—¥ã¯å¤–ã®æ°—æ¸©ãŒä½ã„ã®ã§ã€æ¸©ã‹ã„ä¸Šç€ã‚’ç€ã‚‹ã®ãŒãŠã™ã™ã‚ã§ã™ã‚ˆã€‚(5~10åº¦å‰å¾Œã¿ãŸã„ã§ã™ã‚ˆ)",
                name="ä¸Šç€ã‚’ç€ã‚‹",
                time=0,
                next_state="ãƒˆã‚¤ãƒ¬ã«è¡Œã",
                title="ä¸Šç€ã‚’ç€ã‚‹"
            ),
            State(
                detail="é´ä¸‹ã¨ä¸Šç€ã®æº–å‚™ãŒæ¸ˆã‚“ã ã‚‰ã€å¿µã®ãŸã‚ãƒˆã‚¤ãƒ¬ã‚’æ¸ˆã¾ã›ã¦ãŠãã¨å®‰å¿ƒã§ã™ã­ã€‚",
                name="ãƒˆã‚¤ãƒ¬ã«è¡Œã",
                time=0,
                next_state="é´ç®±ã«å‘ã‹ã†",
                title="ãƒˆã‚¤ãƒ¬ã«è¡Œã"
            ),
            State(
                detail="ãã‚Œã§ã¯ã€1éšã®é´ç®±ã«å‘ã‹ã„ã¾ã—ã‚‡ã†ã€‚",
                name="é´ç®±ã«å‘ã‹ã†",
                time=0,
                next_state="ä¸å®‰ã‚’å–ã‚Šé™¤ã",
                title="é´ç®±ã«å‘ã‹ã†"
            ),
            State(
                detail="ã‚¹ãƒªãƒƒãƒ‘ã®ã¾ã¾ã§ã„ã„ã®ã‹ã€é´ã¯ã©ã“ã«ã‚ã‚‹ã®ã‹ä¸å®‰ã«ãªã‚‹ã“ã¨ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€ä¸‹ã«é´ç®±ãŒã‚ã‚‹ã®ã§å¤§ä¸ˆå¤«ã§ã™ã‚ˆã€‚",
                name="ä¸å®‰ã‚’å–ã‚Šé™¤ã",
                time=1,
                next_state="çµ‚äº†",
                title="ä¸å®‰ã‚’å–ã‚Šé™¤ã"
            ),
            State(
                detail="ã“ã‚Œã§æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãŠæ°—ã‚’ã¤ã‘ã¦ã„ã£ã¦ã‚‰ã£ã—ã‚ƒã„ï¼",
                name="çµ‚äº†",
                time=0,
                next_state="çµ‚äº†",
                title="ãŠæ°—ã‚’ã¤ã‘ã¦ï¼"
            ),
        ]   


    def set_mode(self, mode: bool):
        self.is_on = mode

    def get_mode(self):
        return self.is_on

    async def set_context(self, context: str):
        await self.__deal_user_response(context)

    async def __deal_user_response(self, response: str):
        self.global_responses_buffer.append(response)

        if self.current_state_index >= len(self.states):
            return

        if not self.is_on:
            return

        if "assistant" in response and not self.is_explained:
            print(f"global_responses_buffer: {self.global_responses_buffer}, responses_buffer: {self.responses_buffer}, detail: {self.states[self.current_state_index].detail}")
            thought, result = await self.check_is_explained(self.global_responses_buffer, self.responses_buffer, self.states[self.current_state_index].detail)
            print(f"Check is explained thought: {thought}")
            if result:
                self.is_explained = True
            else:
                await self.direct_prompting_func(
                    f"æ¬¡ã®å†…å®¹ã«ã¤ã„ã¦å¯èƒ½ãªé™ã‚Šæ—©ã„æ®µéšã§ä¼ãˆã¦ãã ã•ã„ã€‚ãŸã ã—å¯¾è©±ã®æ–‡è„ˆã‚’å£Šã•ãªã„ã‚ˆã†ã«å°‘ã—è¨€ã„æ–¹ã‚’å¤‰ãˆã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚å†…å®¹: {self.states[self.current_state_index].detail}, ã¾ãŸå ´åˆã«ã‚ˆã£ã¦ã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã‚“ã§ã‚‚ã„ã„ã§ã™ã€‚ï¼ˆæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å†…å®¹{self.states[min(self.current_state_index+1, len(self.states)-1)].detail}",
                    self.states[self.current_state_index].title  # ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½åŠ 
                )
        elif "user" in response and self.is_explained:
            self.responses_buffer.append(response)
            print(f"global_responses_buffer: {self.global_responses_buffer}, responses_buffer: {self.responses_buffer}, detail: {self.states[self.current_state_index].detail}, next_state: {self.states[self.current_state_index].next_state}")
            thought, is_finished = await self.check_is_finished(self.global_responses_buffer, self.responses_buffer, self.states[self.current_state_index].detail, self.states[self.current_state_index].next_state)
            print(f"Check is finished thought: {thought}")
            if is_finished:
                self.responses_buffer = []
                await self.proceed_to_next_state()
                self.is_explained = False
            else:
                await self.direct_prompting_func(
                    f"æ¬¡ã®å†…å®¹ã«ã¤ã„ã¦å¯èƒ½ãªé™ã‚Šæ—©ã„æ®µéšã§ä¼ãˆã¦ãã ã•ã„ã€‚ã™ã§ã«ä¼ãˆã¦ã„ã‚‹å ´åˆã¯ã€ã‚†ã£ãã‚Šã¨å‚¾è´ã—ç©æ¥µçš„ã«åå¿œã‚’å¼•ãå‡ºã—ãŸã‚Šè¿½åŠ ã§æ˜ã‚Šä¸‹ã’ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚å†…å®¹: {self.states[self.current_state_index].detail}, ã¾ãŸå ´åˆã«ã‚ˆã£ã¦ã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã‚“ã§ã‚‚ã„ã„ã§ã™ã€‚ï¼ˆæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å†…å®¹{self.states[min(self.current_state_index+1, len(self.states)-1)].detail}",
                    self.states[self.current_state_index].title  # ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½åŠ 
                )

        if self.timer:
            self.timer.cancel()

        if self.current_state_index < len(self.states):
            current_state = self.states[self.current_state_index]
            if current_state.time > 0:
                self.timeout_count = 0
                await self.set_timer()

    async def proceed_to_next_state(self):
        self.current_state_index += 1
        self.state_changed = True  # çŠ¶æ…‹ãŒå¤‰åŒ–ã—ãŸã“ã¨ã‚’è¨˜éŒ²

        # ãƒ•ãƒ©ã‚°ã‚„ãƒãƒƒãƒ•ã‚¡ã®ãƒªã‚»ãƒƒãƒˆ
        self.is_explained = False
        self.responses_buffer.clear()
        self.global_responses_buffer.clear()

        print(f"current_state_index: {self.current_state_index}, states: {self.states}")
        if self.current_state_index >= len(self.states):
            await self.end_conversation()
        else:
            await self.send_next_message()

    async def send_next_message(self):
        if self.current_state_index < len(self.states):
            current_state = self.states[self.current_state_index]
            # direct_prompting_func ã« title ã‚’è¿½åŠ ã§æ¸¡ã™ã‚ˆã†ã«ä¿®æ­£
            await self.direct_prompting_func(
                f"Planing Systemã‹ã‚‰è¦è«‹ã§ã™ã€‚æ¬¡ã®å†…å®¹ã«ã¤ã„ã¦å¯èƒ½ãªé™ã‚Šæ—©ã„æ®µéšã§ä¼ãˆã¦ãã ã•ã„ã€‚ãªãŠã€å†…å®¹ãŒä¸è‡ªç„¶ãªå ´åˆã¯æ–‡è„ˆãŒå£Šã‚Œãªã„ã‚ˆã†ã«å°‘ã—è¨€ã„æ–¹ã‚’å¤‰ãˆã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚** å†…å®¹: {current_state.detail}**, ã¾ãŸå ´åˆã«ã‚ˆã£ã¦ã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã‚“ã§ã‚‚ã„ã„ã§ã™ã€‚ï¼ˆæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å†…å®¹{self.states[min(self.current_state_index+1, len(self.states)-1)].detail}",
                current_state.title  # ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½åŠ 
            )

    async def set_timer(self):
        current_state = self.states[self.current_state_index]
        if current_state.time > 0:
            self.timer = asyncio.create_task(self.timeout_handler(current_state.time))

    async def timeout_handler(self, minutes: int):
        await asyncio.sleep(minutes * 60)
        self.timeout_count += 1
        if self.timeout_count >= 2:
            await self.end_conversation()
        else:
            await self.direct_prompting_func(
                f"å¿œç­”ãŒãªã„ã§ã™ãŒã€æº–å‚™ä¸­ã‹ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€é€²è¡Œã«ã¤ã„ã¦ä¼ºã£ã¦ãã ã•ã„ã€‚ : {self.current_state.detail}",
                self.states[self.current_state_index].title  # ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿½åŠ 
            )

    async def end_conversation(self):
        await self.direct_prompting_func("ä¼šè©±ã‚’çµ‚äº†ã—ã¾ã™ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚", "çµ‚äº†")
        self.is_on = False
        if self.callback:
            await self.callback()

    async def run(self, is_debug: bool = False):
        self.is_on = True
        if is_debug:
            print("<Run> called")

        await self.send_next_message()

        while self.is_on:
            await asyncio.sleep(0.1)

    # check_is_explained ã®å®Ÿè£…
    async def check_is_explained(self, global_responses: List[str], responses: List[str], detail: str) -> tuple[str, bool]:
        try:
            response = check_is_explained_chain.invoke({
                "global_responses": global_responses,
                "responses": responses,
                "detail": detail
            })
            return response["thought"], response["is_explained"]
        except Exception as e:
            print(f"Error in check_is_explained: {e}")
            return "Error in check_is_explained", False

    # check_is_finished ã®å®Ÿè£…
    async def check_is_finished(self, global_responses: List[str], responses: List[str], detail: str, next_state_name: str) -> tuple[str, bool]:
        response = check_is_finished_chain.invoke({
            "global_responses": global_responses,
            "responses": responses,
            "detail": detail,
            "next_state_name": next_state_name
        })
        return response["thought"], response["is_finished"]

    def main(self, send_socket, get_messages):
        self.send_socket = send_socket
        self.set_callbacks(self.callback, self.direct_prompting_func)

        # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§Controllerã‚’å®Ÿè¡Œ
        loop = asyncio.new_event_loop()
        self.thread = threading.Thread(target=self.run_controller, args=(loop, self))
        self.thread.start()

    def run_controller(self, loop, controller):
        asyncio.set_event_loop(loop)
        self.loop = loop  # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä¿å­˜
        loop.run_until_complete(controller.run(is_debug=True))

    def schedule_proceed_to_next_state(self):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å†…ã§ proceed_to_next_state ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã¾ã™ã€‚
        """
        if self.loop:
            asyncio.run_coroutine_threadsafe(self.proceed_to_next_state(), self.loop)
        else:
            # ãƒ«ãƒ¼ãƒ—ãŒã¾ã åˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€æ–°ãŸã«ä½œæˆ
            self.loop = asyncio.new_event_loop()
            asyncio.run_coroutine_threadsafe(self.proceed_to_next_state(), self.loop)

    async def set_message(self, message):
        if "user" in message:
            await self.set_context(f"user : {message}")
        elif "assistant" in message:
            await self.set_context(f"assistant : {message}")

    def callback(self):
        best_prob_item = self.uot_controller.uot.root.get_best_prob_item()
        instruction = f"æ¬¡ã®è¡Œå‹•ã®æŒ‡ç¤ºå‡ºã—ã‚’è¡Œã£ã¦ãã ã•ã„: {best_prob_item.name} - {best_prob_item.description}"
        self.send_socket("instruction", {"instruction": instruction, "isLendingEar": False})
        self.stop()

    def direct_prompting_func(self, prompt, title=None):
        if self.state_changed:
            # çŠ¶æ…‹å¤‰åŒ–æ™‚ã¯ 'telluser' ã‚¤ãƒ™ãƒ³ãƒˆã‚’ä½¿ç”¨
            self.send_socket("telluser", {"titles": title, "detail": prompt})
            self.state_changed = False  # çŠ¶æ…‹å¤‰åŒ–ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        else:
            # ãã‚Œä»¥å¤–ã¯ 'instruction' ã‚¤ãƒ™ãƒ³ãƒˆã‚’ä½¿ç”¨
            self.send_socket("instruction", {"instruction": prompt, "isLendingEar": False})

    def stop(self):
        if self.thread and self.thread.is_alive():
            self.set_mode(False)
            self.thread.join()
            self.thread = None

# ä½¿ç”¨ä¾‹
async def main():
    async def mock_direct_message_callback(message, is_repeat=False, is_end=False):
        print(f"Direct Message: {message}")

    async def mock_callback():
        print("Conversation ended.")

    controller = LinearConversationController(fast_model)
    controller.set_callbacks(mock_callback, mock_direct_message_callback)

    asyncio.create_task(controller.run(is_debug=True))

    test_messages = [
        "assistant: ã¯ã„ã€ãƒ‡ã‚¤ã‚µãƒ¼ãƒ“ã‚¹ã®æº–å‚™ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚",
        "user: ã‚ã‹ã‚Šã¾ã—ãŸã€‚æº–å‚™ã‚’å§‹ã‚ã¾ã™ã€‚",
        "assistant: æ¬¡ã¯æœé£Ÿã«ã¤ã„ã¦ãŠè©±ã—ã—ã¾ã™ã€‚",
        "user: æœé£Ÿã‚’æ¸ˆã¾ã›ã¾ã—ãŸã€‚",
        "assistant: æ´—é¡”ã¨é«­å‰ƒã‚Šã®æ™‚é–“ã§ã™ã€‚",
        "user: çµ‚ã‚ã‚Šã¾ã—ãŸã€‚",
        "assistant: ç€æ›¿ãˆã«ã¤ã„ã¦ææ¡ˆã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚",
        "user: ç€æ›¿ãˆã‚‚å®Œäº†ã—ã¾ã—ãŸã€‚",
        "assistant: ãŠè¿ãˆã®æ™‚é–“ãŒè¿‘ã¥ã„ã¦ã„ã¾ã™ã­ã€‚",
        "user: ã¯ã„ã€æº–å‚™ãŒã§ãã¾ã—ãŸã€‚",
    ]

    for message in test_messages:
        await controller.set_context(message)
        await asyncio.sleep(1)

    while controller.get_mode():
        await asyncio.sleep(0.1)

if __name__ == "__main__":
    asyncio.run(main())
